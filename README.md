# ðŸš¦ tfl-realtime-lakehouse

[![Status](https://img.shields.io/badge/status-in_progress-yellow)](#)
[![Airflow](https://img.shields.io/badge/orchestration-Airflow-blue)](#)
[![dbt+DuckDB](https://img.shields.io/badge/transform-dbt%20%2B%20DuckDB-blue)](#)
[![GX](https://img.shields.io/badge/data%20quality-Great%20Expectations-blue)](#)
[![OpenLineage+Marquez](https://img.shields.io/badge/lineage-OpenLineage%20%2B%20Marquez-blue)](#)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

A laptop-friendly, **zero-cost** data engineering project:
- **Ingest (real-time)**: Retrieve live arrival information from the **TfL Unified API**.
- **Action**: Save the data as **Parquet** format in a specified local data lake folder.
- **Transformation**: Use the **dbt + DuckDB** model to move data from staging to marts.
- **Validation**: **Great Expectations** compliance checks.
- **Observation**: **OpenLineage and Marquez** are used for tracking data lineage.

---

## Table of Contents
- [Project Structure](#project-structure)
- [Quick Start](#quick-start)
- [Architecture](#architecture)
- [Tech Stack](#tech-stack)
- [DAGs](#dags)
- [Data Quality](#data-quality)
- [Lineage](#lineage)
- [Roadmap](#roadmap)
- [Attribution & Credits](#attribution--credits)
- [License](#license)

---

## Project Structure

tfl-realtime-lakehouse/

  â”œâ”€ airflow/
  
  â”‚   â”œâ”€ dags/
  
  â”‚   â”‚   â”œâ”€ tfl_ingest_dag.py
  
  â”‚   â”‚   â””â”€ tfl_transform_dag.py
  
  â”‚   â””â”€ requirements.txt
  
  â”œâ”€ dbt_project/
  
  â”‚   â”œâ”€ dbt_project.yml
  
  â”‚   â”œâ”€ models/{staging,marts}/
  
  â”‚   â””â”€ profiles.yml   # Local DuckDB profile.
  
  â”œâ”€ great_expectations/  # Created by GX Initialisation.
  
  â”œâ”€ data/{raw,silver}/   # Mounted volumes.
  
  â”œâ”€ docker-compose.yml
  
  â”œâ”€ .env                 # (Create from .env.example; contains TFL keys).
  
  â”œâ”€ README.md
  
  â””â”€ LICENSE

